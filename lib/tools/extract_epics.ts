import { tool } from "langchain";
import {
  generateEpicsInputSchema,
  generateEpicsOutputSchema,
} from "../schemas/epicSchema";
import { epicPrompt } from "../prompts/epicPrompt";
import { model } from "../ai/client";

const log = {
  info: (message: string, data?: unknown) =>
    console.log(`[generate_epics][INFO] ${message}`, data ?? ""),
  error: (message: string, data?: unknown) =>
    console.error(`[generate_epics][ERROR] ${message}`, data ?? ""),
};

export const generateEpicsTool = tool(
  async (input) => {
    try {
      log.info("Tool iniciada", input);

      // üîí Valida√ß√£o expl√≠cita de input
      const { projectText } = generateEpicsInputSchema.parse(input);

      // üß† Simula√ß√£o de sa√≠da do LLM
    const prompt = epicPrompt(projectText);
    const llmResponse = await model.invoke(prompt);
    const rawOutput = JSON.parse(llmResponse.content as string);
    return generateEpicsOutputSchema.parse(rawOutput);
    } catch (error) {
      log.error("Falha ao gerar √©picos", error);

      throw new Error(
        "Erro ao processar o texto do projeto para gerar √©picos"
      );
    }
  },
  {
    name: "generate_epics",
    description: "Extrai √©picos (grandes objetivos) a partir da descri√ß√£o do projeto",
    schema: generateEpicsInputSchema,
  }
);
